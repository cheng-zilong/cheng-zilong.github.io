<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Cheng-Zilong">
<meta property="og:url" content="http://yoursite.com/page/5/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cheng-Zilong">
  <link rel="canonical" href="http://yoursite.com/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/4.6 Proximal Algorithms/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/4.6 Proximal Algorithms/" class="post-title-link" itemprop="url">4. Gradient Methods (2) - Proximal Algorithms</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-31 19:37:15" itemprop="dateModified" datetime="2019-10-31T19:37:15+08:00">2019-10-31</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="proximal-algorithms">4.6 Proximal Algorithms</h2>
<p>In this section, some important algorithms for solving convex optimization problems will rely on the use of proximal operators.</p>
<h3 id="proximal-minimization">4.6.1 Proximal minimization</h3>
<p>The <strong>proximal minimization algorithm</strong>, also called <strong>proximal iteration</strong> or <strong>proximal point algorithm</strong>, is <span class="math display">\[
x^{k+1}=P_{\lambda f}(x^k),
\]</span> where <span class="math inline">\(f:\mathbb R^n \rightarrow \mathbb R\cup \{+\infty\}\)</span> is a closed proper convex function, <span class="math inline">\(k\)</span> is the iteration number, and <span class="math inline">\(x^k\)</span> denotes the <span class="math inline">\(k\)</span>th iterate of the algorithm. We have shown that <span class="math inline">\(x^k\)</span> will converge to the optimal value. A variation of this method is to replace the constant <span class="math inline">\(\lambda\)</span> with <span class="math inline">\(\lambda^k\)</span>. Convergence is guaranteed provided <span class="math inline">\(\lambda^k&gt;0\)</span> and <span class="math inline">\(\sum_{k=1}^\infty \lambda^k=\infty\)</span>.</p>
<p><strong>Interpretations</strong></p>
<p>The proximal minimization algorithm an be interpreted many ways. One simple perspective is that it is the standard gradient method applied to the Moreau envelope <span class="math inline">\(M_f\)</span> rather than <span class="math inline">\(f\)</span>. Another is that it is simple iteration for finding a fixed point of <span class="math inline">\(P_{\lambda f}\)</span>, which works because <span class="math inline">\(P_{\lambda f}\)</span> is firmly nonexpansive.</p>
<p><em>Disappearing Tikhonov regularization</em></p>
<p>Another simple interpretation is a quadratic regularization centered at the previous iterate <span class="math inline">\(x^k\)</span>. In each step, we solve the regularized problem, <span class="math display">\[
\min_x f(x)+(1/2\lambda)||x-x^k||_2^2.
\]</span></p>
<p>The second term can be interpreted as regularization centered at the previous iterate <span class="math inline">\(x^k\)</span>. It is a damping term that encourages <span class="math inline">\(x^{k+1}\)</span> not to be very far from <span class="math inline">\(x^k\)</span>. As the proximal algorithm converges, <span class="math inline">\(x^{k+1}\)</span> gets close to <span class="math inline">\(x^k\)</span>, so the effect of the quadratic regularization goes to zero.</p>
<p><em>Gradient flow</em></p>
<p>Proximal minimization can be interpreted as a discretized method for solving a differential equation whose equilibrium points are the minimizers of a differentiable convex function <span class="math inline">\(f\)</span>. The differential equation <span class="math display">\[
\frac{d}{dt}x(t)=-\nabla f(x(t)),
\]</span> with variable <span class="math inline">\(x:\mathbb R_+\rightarrow \mathbb R^n\)</span>, is called the gradient flow for <span class="math inline">\(f\)</span>. The equilibrium points of the gradient flow are the zeros of <span class="math inline">\(\nabla f\)</span>, which are exactly the minimizers of <span class="math inline">\(f\)</span>.</p>
<p>My thinking is that <span class="math inline">\(\dot x(t)\)</span> is the velocity in some position <span class="math inline">\(x(t)\)</span>, and the velocity is actually the gradient of the function in the position <span class="math inline">\(x(t)\)</span>. So the next position will go alongside the velocity.</p>
<p>The idea of the gradient flow can be generalized to cases where <span class="math inline">\(f\)</span> is not differentiable via the subgradient differential inclusion, <span class="math display">\[
\frac{d}{dt}x(t)\in-\partial f(x(t)).
\]</span> Let <span class="math inline">\(x^k\)</span> be the approximation of <span class="math inline">\(x(kh)\)</span>, where <span class="math inline">\(h&gt;0\)</span> is a small step size. The simplest discretization is <span class="math display">\[
\frac{x^{k+1}-x^k}{h}=-\nabla f(x^k),
\]</span> known as the <strong>forward Euler discretization</strong>. Then we have <span class="math display">\[
x^{k+1}=x^k-h\nabla f(x^k).
\]</span> This is the standard gradient descent iteration with step size <span class="math inline">\(h\)</span>.</p>
<p>The <strong>backward Euler method</strong> uses the discretization, <span class="math display">\[
\frac{x^{k+1}-x^k}{h}=-\nabla f(x^{k+1}).
\]</span> This method is known to have better approximation properties than forward Euler, especially for differential equations that converge. Its main disadvantage is that it cannot be rewritten as an iteration that gives <span class="math inline">\(x^{k+1}\)</span> <strong>explicitly</strong> in terms of <span class="math inline">\(x^k\)</span>. For this reason, it is also called <strong>implicit method</strong>. To find <span class="math inline">\(x^{k+1}\)</span>, we solve the equation, <span class="math display">\[
x^{k+1}+h\nabla f(x^{k+1})=x^k,
\]</span> which is equivalent to <span class="math display">\[
x^{k+1}=P_{h\lambda}(x^k),
\]</span> by using <span class="math inline">\(P_{\lambda f}=(I+\lambda \partial f)^{-1}\)</span>.</p>
<p>Thus, the proximal minimization method is the backward Euler method for numerical integration applied to the gradient flow differential equation. The parameter <span class="math inline">\(\lambda\)</span> in the standard proximal minimization method corresponds to the time step used in the discretization.</p>
<h3 id="proximal-gradient-method">4.6.2 Proximal gradient method</h3>
<p>Consider the problem <span class="math display">\[
\min f(x)+g(x),
\]</span> where <span class="math inline">\(f:\mathbb R^n\rightarrow \mathbb R\)</span> and <span class="math inline">\(g:\mathbb R^n\rightarrow \mathbb R\cup\{+\infty\}\)</span> are closed proper convex and <span class="math inline">\(f\)</span> is differentiable. Since <span class="math inline">\(g\)</span> can be extended valued, it can be used to encode constraints on the variable <span class="math inline">\(x\)</span>. The proximal gradient method is <span class="math display">\[
x^{k+1}=P_{\lambda^k g}(x^k-\lambda ^k\nabla f(x^k)),
\]</span> where <span class="math inline">\(\lambda ^k&gt;0\)</span> is a step size.</p>
<p>When <span class="math inline">\(\nabla f\)</span> is Lipschitz continuous with constant <span class="math inline">\(L\)</span>, this method can be shown to converge with rate <span class="math inline">\(\mathcal O(1/k)\)</span> when a fixed step size <span class="math inline">\(\lambda^k=\lambda \in (0,1/L]\)</span> is used. If <span class="math inline">\(L\)</span> is not known, the step sizes <span class="math inline">\(\lambda^k\)</span> can be found by a line search, that is, their values are chosen in each step. The simple one is shown in the following (by Beck and Teboulle).</p>
<hr>
<p><strong>Given</strong> <span class="math inline">\(x^k\)</span>, <span class="math inline">\(\lambda^{k-1}\)</span>, and parameter <span class="math inline">\(\beta \in (0,1)\)</span>.</p>
<p><strong>Let</strong> <span class="math inline">\(\lambda = \lambda^{k-1}\)</span>.</p>
<p><strong>Repeat</strong></p>
<ol type="1">
<li>Let <span class="math inline">\(z=P_{\lambda g}(x^k-\lambda \nabla f(x^k))\)</span>.</li>
<li><strong>Break</strong> if <span class="math inline">\(f(z)\le \hat f_\lambda(z,x^k)\)</span>.</li>
<li><strong>Update</strong> <span class="math inline">\(\lambda = \beta \lambda\)</span>.</li>
</ol>
<p><strong>Return</strong> <span class="math inline">\(\lambda^k=\lambda\)</span>, <span class="math inline">\(x^{k+1}=z\)</span>.</p>
<hr>
<p><strong>Special cases</strong></p>
<p>The proximal gradient method reduces to other well-known algorithms in various special cases. When <span class="math inline">\(g=\delta_\mathcal C\)</span>, <span class="math inline">\(P_{\lambda g}\)</span> is projection onto <span class="math inline">\(\mathcal C\)</span>, in which cases it reduces to the <strong>projected gradient method</strong>. When <span class="math inline">\(f=0\)</span>, then it reduces to <strong>proximal minimization</strong>, and when <span class="math inline">\(g=0\)</span>, it reduces to the standard <strong>gradient descent method</strong>.</p>
<p><strong>Interpretations</strong></p>
<p><em>Majorization-minimization</em></p>
<p>We first interpret the proximal gradient method as an example of a majorization-minimization algorithm, a large class of algorithms that includes the gradient method, Newtonâ€™s method, and the EM algorithm as special cases.</p>
<p>A <strong>majorization-minimization</strong> algorithm for minimizing a function <span class="math inline">\(\varphi:\mathbb R^n\rightarrow \mathbb R\)</span> consists of the iteration, <span class="math display">\[
x^{k+1}=\arg\min_{x}\hat \varphi (x,x^k),
\]</span> where <span class="math inline">\(\hat \varphi(\cdot,x^k)\)</span> is a convex upper bound to <span class="math inline">\(\varphi\)</span> that is tight at <span class="math inline">\(x^k\)</span>, i.e., <span class="math inline">\(\hat \varphi(x,x^k)\ge \varphi(x)\)</span> and <span class="math inline">\(\hat \varphi(x,x)= \varphi(x)\)</span> for all <span class="math inline">\(x\)</span>. The reason for the name should be clear, such algorithms involve iteratively majorizing (upper bounding) the objective and then minimizing the majorization.</p>
<p>For an upper bound of <span class="math inline">\(f\)</span>, consider the function <span class="math inline">\(\hat f_{\lambda }\)</span> given by <span class="math display">\[
\hat f_{\lambda}(x,y)=f(y)+\nabla f(y)^T(x-y)+(1/2\lambda)||x-y||_2^2,
\]</span> with <span class="math inline">\(\lambda&gt;0\)</span>. For fixed <span class="math inline">\(y\)</span>, this function is convex, satisfies <span class="math inline">\(\hat f_\lambda (x,x)=f(x)\)</span>, and is an upper bound on <span class="math inline">\(f\)</span> when <span class="math inline">\(\lambda \in (0,1/L]\)</span>, where <span class="math inline">\(L\)</span> is a Lipschitz constant of <span class="math inline">\(\nabla f\)</span>. The algorithm <span class="math display">\[
x^{k+1}=\arg\min_x\hat f_\lambda (x,x^k)
\]</span> is thus majorization-minimization algorithm. In fact, it is precisely the standard gradient method for minimizing <span class="math inline">\(f\)</span>.</p>
<p>Then the function <span class="math inline">\(q_\lambda\)</span> given by <span class="math display">\[
q_\lambda(x,y)=\hat f_\lambda(x,y)+g(x)
\]</span> is similarly a surrogate for <span class="math inline">\(f+g\)</span> when <span class="math inline">\(\lambda \in (0,1/L]\)</span>. The majorization-minimization algorithm, <span class="math display">\[
x^{k+1}=\arg\min_x q_\lambda (x,x^k)
\]</span> can be shown to be equivalent to the proximal gradient iteration, <span class="math display">\[
x^{k+1}=P_{\lambda^k g}(x^k-\lambda ^k\nabla f(x^k)).
\]</span> <em>Fixed point iteration</em></p>
<p>The proximal gradient algorithm can also be interpreted as a fixed point iteration. A point <span class="math inline">\(x^*\)</span> is a minimizer if and only if <span class="math display">\[
0\in\nabla f(x^*)+\partial g(x^*).
\]</span> For any <span class="math inline">\(\lambda &gt;0\)</span>, this optimality condition holds if and only if the following equivalent statements hold, <span class="math display">\[
\begin{array}{rcl}
0 &amp;\in&amp; \lambda\nabla f(x^*)+\lambda\partial g(x^*)\\
0 &amp;\in&amp; \lambda\nabla f(x^*)-x^*+x^*+\lambda\partial g(x^*)\\
(I+\lambda \partial g)(x^*) &amp;\ni&amp; (I-\lambda\nabla f)(x^*)\\
x^* &amp;=&amp; (I+\lambda \partial g)^{-1}(I-\lambda\nabla f)(x^*)\\
x^* &amp;=&amp; P_{\lambda g}(x^*-\lambda\nabla f(x^*)).
\end{array}
\]</span> The last two expressions hold with equality because proximal operator is single valued.</p>
<p>The last two expression says that <span class="math inline">\(x^*\)</span> minimizes <span class="math inline">\(f+g\)</span> if and only if it is a fixed point of the <strong>forward-backward operator</strong>, <span class="math display">\[
(I+\lambda \partial g)^{-1}(I-\lambda\nabla f).
\]</span> <em>Forward-backward integration of gradient flow</em></p>
<p>The proximal gradient method can be interpreted using <strong>gradient flows</strong>. <span class="math display">\[
\frac{d}{dt}x(t)=-\nabla f(x(t))-\nabla g(x(t)),
\]</span> assuming that <span class="math inline">\(g\)</span> is also differentiable.</p>
<p>Then we consider the following discretization, <span class="math display">\[
\frac{x^{k+1}-x^k}{h}=-\nabla f(x^k)-\nabla g(x^{k+1}).
\]</span> Then we have <span class="math display">\[
x^{k+1} = (I+h \nabla g)^{-1}(I-\lambda\nabla f)x^k.
\]</span></p>
<h3 id="accelerated-proximal-gradient-method">4.6.3 Accelerated proximal gradient method</h3>
<p>So-called accelerated versions of the basic proximal gradient algorithm include an extrapolation step in the algorithm. One simple version is <span class="math display">\[
y^{k+1}=x^k+w^k(x^k-x^{k-1})\\
x^{k+1}=P_{\lambda^kg}(y^{k+1}-\lambda^k \nabla f(y^{k+1})).
\]</span> These parameters must be chosen in specific ways to achieve the convergence acceleration. One simple choice takes <span class="math display">\[
w^k=\frac{k}{k+3}.
\]</span> When <span class="math inline">\(\nabla f\)</span> is Lipschitz continuous with constant <span class="math inline">\(L\)</span>, this method can be shown to converge in objective value with rate <span class="math inline">\(\mathcal O(1/k^2)\)</span> when a fixed step size <span class="math inline">\(\lambda^k=\lambda \in(0,1/L]\)</span> is used. If <span class="math inline">\(L\)</span> is not known, the step sizes <span class="math inline">\(\lambda^k\)</span> can be found by a line search.</p>
<h3 id="alternating-direction-method-of-multipliers">4.6.4 Alternating direction method of multipliers</h3>
<p>Consider the problem, <span class="math display">\[
\min f(g)+g(x)
\]</span> where <span class="math inline">\(f,g:\mathbb R^n\rightarrow \mathbb R\cup \{+\infty\}\)</span> are closed proper convex functions. Both <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> can be nonsmoothed. Then the <strong>alternating direction method of multipliers (ADMM)</strong> also known as <strong>Douglas-Rachford splitting</strong> is <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;P_{\lambda f} (z^k-u^k)\\
z^{k+1}&amp;=&amp; P_{\lambda g}(x^{k+1}+u^k)\\
u^{k+1}&amp;=&amp; u^k+x^{k+1}-z^{k+1}.
\end{array}
\]</span> This method converges under more or less the most general possible conditions.</p>
<p>While <span class="math inline">\(x^k\)</span> and <span class="math inline">\(z^k\)</span> converge to each other, and to optimality, they have slightly different properties. For example, <span class="math inline">\(x^k\in \text{dom}f\)</span> while <span class="math inline">\(z^k\in \text{dom}g\)</span>, so if <span class="math inline">\(g\)</span> encodes constraints, the iterates <span class="math inline">\(z^k\)</span> satisfy the constraints while the iterates <span class="math inline">\(x^k\)</span> satisfy the constraints only in the limit. If <span class="math inline">\(g=||\cdot||_2\)</span>, then <span class="math inline">\(z^k\)</span> will be sparse because <span class="math inline">\(P_{\lambda g}\)</span> is soft thresholding, while <span class="math inline">\(x^k\)</span> will only be close to <span class="math inline">\(z^k\)</span> (close to sparse).</p>
<p>The advantage of ADMM is that the objective terms (which can both include constraints, since they can take on infinite values) are handle completely separately, the functions are accessed only through their proximal operators. ADMM is most useful when the proximal operators of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> can be efficiently evaluated but the proximal operator for <span class="math inline">\(f+g\)</span> is not easy to evaluate.</p>
<p><strong>Special cases</strong></p>
<p>When <span class="math inline">\(g\)</span> is the indicator function of a closed convex set <span class="math inline">\(\mathcal C\)</span>, its proximal operator <span class="math inline">\(P_{\lambda g}\)</span> reduces to projection onto <span class="math inline">\(\mathcal C\)</span>. In this case, ADMM is a method for solving the generic convex constrained problem of minimizing <span class="math inline">\(f\)</span> over <span class="math inline">\(\mathcal C\)</span>, that only uses the proximal operator of the objective and projection onto the constraint set. As further specialization, suppose that <span class="math inline">\(f\)</span> is the indicator function of a closed convex set <span class="math inline">\(\mathcal C\)</span> and <span class="math inline">\(g\)</span> is the indicator function of a closed convex set <span class="math inline">\(\mathcal D\)</span>. The problem of minimizing <span class="math inline">\(f+g\)</span> is then equivalent to the convex feasibility problem of finding a point <span class="math inline">\(x\in\mathcal C\cap \mathcal D\)</span>. Both proximal operators reduce to projections, so the ADMM algorithm for this problem becomes, <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;\Pi_\mathcal C (z^k-u^k)\\
z^{k+1}&amp;=&amp; \Pi_\mathcal D (x^{k+1}+u^k)\\
u^{k+1}&amp;=&amp; u^k+x^{k+1}-z^{k+1}.
\end{array}
\]</span> <strong>Interpretations</strong></p>
<p><em>Integral control of a dynamic system</em></p>
<p>The first two steps in ADMM can be viewed as a discrete-time dynamic system with state <span class="math inline">\(z\)</span> and input or control <span class="math inline">\(u\)</span>, i.e., <span class="math inline">\(z^{k+1}\)</span> is a function of <span class="math inline">\(x^k\)</span> and <span class="math inline">\(u^k\)</span>. The goal is to choose <span class="math inline">\(u\)</span> to achieve <span class="math inline">\(x=z\)</span>, so the residual <span class="math inline">\(x^{k+1}-z^{k+1}\)</span> can be viewed as an error signal.</p>
<p><em>Augmented Lagrangians</em></p>
<p>One important interpretation relies on the idea of <strong>augmented lagrangian</strong>. We first write the problem of minimizing <span class="math inline">\(f(x)+g(x)\)</span> as <span class="math display">\[
\begin{array}{rCl}
\min &amp; f(x)+g(z)\\
\text{subject to}&amp; x-z=0,
\end{array}
\]</span></p>
<p>which is called <strong>consensus form</strong>. Here the variable has been split into two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span>, and we have added the consensus constraint they must agree. This is evidently equivalent to minimizing <span class="math inline">\(f+g\)</span>.</p>
<p>The <strong>augmented Lagrangian</strong> associated with the problem is <span class="math display">\[
L_\rho(x,z;y)=f(x)+g(z)+y^T(x-z)+(\rho/2)||x-z||_2^2,
\]</span> where <span class="math inline">\(\rho&gt;0\)</span> is a parameter and <span class="math inline">\(y\in\mathbb R^n\)</span> is a dual variable associated with the consensus constraint. This is the usual Lagrangian augmented with an additional quadratic penalty on the equality constraint function. ADMM can be then expressed as <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;\arg\min_x L_\rho (x,z^k,y^k)\\
z^{k+1}&amp;=&amp;\arg\min_z L_\rho (x^{k+1},z,y^k)\\
y^{k+1}&amp;=&amp; y^k+\rho(x^{k+1}-z^{k+1}).
\end{array}
\]</span> (<strong>My thinking</strong>) The intuitive explanation of ADMM can be interpreted here. <span class="math inline">\(y^k\)</span> is actually the weighting parameter for the ALM, which balances the error between the parameter <span class="math inline">\(x\)</span> and the parameter <span class="math inline">\(z\)</span>. If <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> are not the same, the weighting of the error will grow up since the value of the <span class="math inline">\(y^k\)</span> can be accumulated. Therefore, the ADMM system will finally converge to the point where the error between <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> is zero, and the value of the ALM is minimized.</p>
<p>In each of the <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> steps, <span class="math inline">\(L_\rho\)</span> is minimized over the variable, using the most resent value of the other primal variable and dual variable. The dual variable is the scaled running sum of the consensus errors. To see how it reduces to the proximal version, we start from <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;\arg\min_x \left(f(x)+\langle y^{k},x\rangle +(\rho/2)||x-z^k||_2^2\right)\\
z^{k+1}&amp;=&amp;\arg\min_z \left(g(z)-\langle y^{k},z\rangle+(\rho/2)||x^{k+1}-z||_2^2\right)\\
y^{k+1}&amp;=&amp; y^k+\rho(x^{k+1}-z^{k+1}).
\end{array}
\]</span> Pull the linear terms into the quadratic ones, and we get <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;\arg\min_x \left(f(x)+(\rho/2)\left\|x-z^k+(1/\rho)y^k\right\|_2^2\right)\\
z^{k+1}&amp;=&amp;\arg\min_z \left(g(z)+(\rho/2)\left\|x^{k+1}-z-(1/\rho)y^k\right\|_2^2\right)\\
y^{k+1}&amp;=&amp; y^k+\rho(x^{k+1}-z^{k+1}).
\end{array}
\]</span> If we choose <span class="math inline">\(u^k=(1/\rho)y^k\)</span> and <span class="math inline">\(\lambda = 1/\rho\)</span>, then we get the ADMM.</p>
<p><em>Flow interpretation</em></p>
<p>ADMM can also be interpreted as a method for solving a particular system of ordinary differential equations. Assume for simplicity that <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are differentiable, the optimality conditions are <span class="math display">\[
\nabla f(x)+v=0,\quad \nabla g(z)-v=0,\quad x-z=0,
\]</span> where <span class="math inline">\(v\in\mathbb R^n\)</span> is a dual variable. Now consider the differential equation <span class="math display">\[
\frac{d}{dt}
\begin{bmatrix}
x(t)\\z(t)
\end{bmatrix}=
\begin{bmatrix}
-\nabla f(x(t))-\rho u(t)-\rho r(t)\\
-\nabla g(x(t))+\rho u(t)+\rho r(t)\\
\end{bmatrix},\quad
\frac{d}{dt}u(t)=\rho r(t),
\]</span> where <span class="math inline">\(r(t)=x(t)-z(t)\)</span> is the primal residual and <span class="math inline">\(\rho &gt;0\)</span>. The functions in the differential equation are the primal variables <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span>, and the dual variable <span class="math inline">\(u\)</span>. It is easy to see that the equilibrium points of the saddle point flow are the same as the optimality conditions when <span class="math inline">\(v=\rho u\)</span>. It shows all trajectories of the saddle point flow converge to an equilibrium point. It follows that we can solve the problem by following any trajectory of the flow using numerical integration.</p>
<p>We use the discretization given by <span class="math display">\[
\frac{x^{k+1}-x^k}{h}=-\nabla f(x^{k+1})-\rho (x^k-z^k+u^k)\\
\frac{z^{k+1}-z^k}{h}=-\nabla g(x^{k+1})+\rho (x^{k+1}-z^k+u^k)\\
\frac{u^{k+1}-u^k}{h}=\rho(x^{k+1}-z^{k+1}).
\]</span> Choosing <span class="math inline">\(h=\lambda\)</span> and <span class="math inline">\(\rho=1/\lambda\)</span>, the discretization reduces directly to the proximal form of ADMM.</p>
<p><em>Fixed point iteration</em></p>
<p>ADMM can be viewed as a fixed point iteration for finding a point <span class="math inline">\(x^*\)</span> satisfying the optimality condition <span class="math display">\[
0\in\partial f(x^*)+\partial g(x^*).
\]</span> Fixed point <span class="math inline">\(x,z,u\)</span> of the ADMM iteration satisfy <span class="math display">\[
x=P_{\lambda f}(z-u),\quad z=P_{\lambda g}(x+u),\quad u=u+x-z.
\]</span> From the last equation we conclude <span class="math inline">\(x=z\)</span>, so <span class="math display">\[
x=P_{\lambda f}(x-u),\quad x=P_{\lambda g}(x+u)
\]</span> which can be written as <span class="math display">\[
x=(I+\lambda \partial f)^{-1}(x-u),\quad x=(I+\lambda \partial g)^{-1}(x+u).
\]</span> This is the same as <span class="math display">\[
x-u\in x+\lambda \partial f(x),\quad x+u\in x+\lambda\partial g(x).
\]</span> Adding these two equations show that <span class="math inline">\(x\)</span> satisfies the optimality condition.</p>
<p><strong>Linearized ADMM</strong></p>
<p>A variation of ADMM can be useful for solving problems of the form, <span class="math display">\[
\min f(x)+g(Ax),
\]</span> where <span class="math inline">\(f:\mathbb R\rightarrow \mathbb R\cup \{+\infty\}\)</span> and <span class="math inline">\(g:\mathbb R\rightarrow \mathbb R\cup \{+\infty\}\)</span> are closed proper convex and <span class="math inline">\(A\in\mathbb R^{m\times n}\)</span>. This problem can be solved with standard ADMM by defining <span class="math inline">\(\tilde g(x)=g(Ax)\)</span> but the proximal operator of <span class="math inline">\(\tilde g\)</span> is complicated by the presence of <span class="math inline">\(A\)</span>, even when the proximal operator of <span class="math inline">\(g\)</span> is easy to evaluate. The linearized ADMM solves the problem using only the proximal operators of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> and multiplication by <span class="math inline">\(A\)</span> and <span class="math inline">\(A^T\)</span>; in particular, <span class="math inline">\(g\)</span> and <span class="math inline">\(A\)</span> are handled separately. <span class="math display">\[
x^{k+1}=P_{\mu f}\left(x^k-(\mu/\lambda )A^T(Ax^k-z^k+u^k)\right)\\
z^{k+1}=P_{\lambda g}\left(Ax^{k+1}+u^k\right)\\
u^{k+1}=u^k+Ax^{k+1}-z^{k+1},
\]</span> where the algorithm parameters <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> satisfy <span class="math inline">\(0\le \mu\le \lambda /||A||_2^2\)</span>. This reduces to standard ADMM when <span class="math inline">\(A=I\)</span> and <span class="math inline">\(\mu =\lambda\)</span>.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/4.1 Gradient methods/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/4.1 Gradient methods/" class="post-title-link" itemprop="url">4. Gradient Methods (1)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-31 22:26:22" itemprop="dateModified" datetime="2019-10-31T22:26:22+08:00">2019-10-31</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="gradient-methods">4. Gradient methods</h1>
<h2 id="gradient-methods-for-unconstrained-optimization-problem">4.1 Gradient methods for unconstrained optimization problem</h2>
<p>Consider the multidimensional unconstrained minimization problem <span class="math display">\[
\begin{array}{rCl}
\text{minimize} &amp; f(x)\\
\text{subject to}&amp; x\in S.
\end{array}
\]</span> In the situation where <span class="math inline">\(\nabla f(x)=0\)</span> cannot be solved analytically, we look for an approximate solution via iterative methods.</p>
<p><strong>General framework of an optimization algorithm</strong></p>
<hr>
<p><strong>For</strong> <span class="math inline">\(k=0,1,...,\)</span> <strong>if</strong> <span class="math inline">\(x^{(k)}\)</span> is optimal stop <strong>else</strong> determine an improved estimate of the solution <span class="math inline">\(x^{(k+1)}=x^{(k)}+\alpha_{k}\times p^{(k)}\)</span> <strong>end</strong> <strong>end</strong></p>
<hr>
<p>Here <span class="math inline">\(p^{(k)}\)</span> is a <strong>search direction</strong> that we hope points towards the solution, or that improves our solution in some sense. The scalar <span class="math inline">\(\alpha_k\)</span> is a step length that determines the point <span class="math inline">\(x^{(k+1)}\)</span>. Once the search direction has been solved, the step length can be solved as some auxiliary one-dimensional problems.</p>
<p><strong>Descent property</strong> At a given point <span class="math inline">\(x^*\)</span>, let <span class="math inline">\(\hat d=-\frac{\nabla f(x^*)}{||\nabla f(x^*)||}\)</span>. The value of <span class="math inline">\(f\)</span> decreases most rapidly along the unit direction <span class="math inline">\(\hat d\)</span> and the rate of change of <span class="math inline">\(f\)</span> at <span class="math inline">\(x^*\)</span> along the direction <span class="math inline">\(\hat d\)</span> is <span class="math inline">\(-||\nabla f(x^*)||\)</span>, i.e., as <span class="math inline">\(x\)</span> moves along <span class="math inline">\(\hat d\)</span> from <span class="math inline">\(x^*\)</span> by a small distance <span class="math inline">\(\delta\)</span>, the value <span class="math inline">\(f(x)\)</span> is changed by the amount <span class="math inline">\(-||\nabla f(x^*)||\delta\)</span>.</p>
<p>In general, a direction <span class="math inline">\(d\)</span> such that <span class="math inline">\(\langle \nabla f(x^*),d\rangle &lt;0\)</span> is called a descent direction.</p>
<p>The direction <span class="math inline">\(-\nabla f(x^*)\)</span> is known as the steepest descent direction since it gives the fastest rate of decrease in <span class="math inline">\(f(x)\)</span> among all directions.</p>
<p><strong>Steepest descent method with exact line search</strong></p>
<hr>
<p><strong>[step 0]</strong> Select an initial point <span class="math inline">\(x^{(0)}\)</span>, and <span class="math inline">\(\epsilon&gt;0\)</span> <strong>[step k]</strong> <strong>For</strong> <span class="math inline">\(k=0,1,...,\)</span></p>
<ol type="1">
<li><p>evaluate <span class="math inline">\(d^{(k)} = -\nabla f(x^{(k)})\)</span></p></li>
<li><p><strong>if</strong> <span class="math inline">\(||d^{(k)}||&lt;\epsilon\)</span>, stop and <span class="math inline">\(x^{(k)}\)</span> is an approximate solution</p>
<p><strong>else</strong></p>
<ol type="1">
<li><p>find the value <span class="math inline">\(t_k\)</span> that minimizes the one-dimensional function <span class="math display">\[
g(t)=f(x^{(k)}+td^{(k)})
\]</span></p></li>
<li><p>set <span class="math inline">\(x^{(k+1)}=x^{(k)}+t_kd^{(k)}\)</span>.</p></li>
</ol></li>
</ol>
<p><strong>end</strong></p>
<hr>
<p><strong>Remark</strong></p>
<p>The most difficult part of the steepest descent method usually is to find the <span class="math inline">\(t_k\)</span> that minimizes <span class="math inline">\(f\)</span> along the gradient direction.</p>
<p><strong>Theorem 4.1</strong> The steepest descent method with exact linesearch moves in <strong>perpendicular</strong> steps.</p>
<p><strong>Remarks</strong></p>
<ol type="1">
<li><p>Monotonic decreasing property</p>
<p>If <span class="math inline">\(x^{(k)}\)</span> is a steepest descent sequence for a function <span class="math inline">\(f(x)\)</span>, and if <span class="math inline">\(\nabla f(x^{(k)})\neq 0\)</span> for some <span class="math inline">\(k\)</span>, then <span class="math inline">\(f(x^{(k+1)})&lt;f(x^{(k)})\)</span>.</p></li>
<li><p>Convergence of a steepest descent method</p>
<p>Suppose <span class="math inline">\(f(x)\)</span> is a coercive function with continuous first derivatives on <span class="math inline">\(\mathbb R^n\)</span>. Let <span class="math inline">\(x^{(0)}\in \mathbb R^n\)</span>. Suppose <span class="math inline">\(\{x^{(k)}\}\)</span> is the steepest descent sequence for <span class="math inline">\(f(x)\)</span> with initial point <span class="math inline">\(x^{(0)}\)</span>. Then some subsequence of <span class="math inline">\(\{x^{(k)}\}\)</span> converges. The limit of any convergent subsequence of <span class="math inline">\(\{x^{(k)}\}\)</span> is a critical point of <span class="math inline">\(f(x)\)</span>.</p></li>
</ol>
<h3 id="convergence-rate-of-the-steepest-descent-method-for-an-unconstrained-convex-quadratic-minimization-problem">4.1.1 Convergence rate of the steepest descent method for an unconstrained convex quadratic minimization problem</h3>
<p>Here we consider <span class="math display">\[
\min_{x\in\mathbb R^n}\; q(x)=\frac{1}{2}x^TQx,
\]</span> where <span class="math inline">\(Q\)</span> is symmetric positive definite.</p>
<p><strong>Proposition</strong></p>
<p>For a symmetric positive definite <span class="math inline">\(Q\)</span>, suppose that <span class="math inline">\(\{x^{(k)}\}\)</span> is a sequence obtained from the steepest descent method with exact line search applied to the function <span class="math inline">\(q(x)\)</span>. Then</p>
<ol type="1">
<li><p>Let <span class="math inline">\(d^{k}=\nabla q(x^k)=Qx^k\)</span>, <span class="math display">\[
\frac{q(x^{k+1})}{q(x^{k})}=1-\frac{\langle d^k,d^k\rangle^2}{\langle d^k,Qd^k\rangle\langle d^k,Q^{-1}d^k\rangle}
\]</span></p></li>
<li><p><span class="math display">\[
\frac{q(x^{k+1})}{q(x^{k})}\le \left[\frac{\kappa (Q)-1}{\kappa (Q)+1}\right]^2=\rho(Q)
\]</span></p>
<p>where <span class="math inline">\(\kappa (Q) = \lambda_n/\lambda_1\)</span>, and <span class="math inline">\(\lambda_n\)</span> and <span class="math inline">\(\lambda_1\)</span> are the largest and smallest eigenvalues of <span class="math inline">\(Q\)</span>, respectively. The number <span class="math inline">\(\kappa(Q)\)</span> is called the condition number of <span class="math inline">\(Q\)</span>. When <span class="math inline">\(\kappa(Q)\ge 1\)</span> is small, say less than <span class="math inline">\(10^3\)</span>, <span class="math inline">\(Q\)</span> is said to be well-conditioned.</p></li>
</ol>
<p>Proof is intuitive and skipped.</p>
<p><strong>Remark</strong></p>
<ol type="1">
<li><p>From proposition, we see that the convergence rate <span class="math inline">\(\rho (Q)\)</span> of the steepest descent method depends on <span class="math inline">\(\kappa(Q)\)</span>. When <span class="math inline">\(\kappa(Q)\)</span> is large, the convergence rate <span class="math display">\[
\rho(Q)\approx 1-\frac{4}{\kappa(Q)}.
\]</span></p></li>
<li><p>The number of iterations needed to reduce the relative error <span class="math inline">\(q(x_k)/q(x_0)\)</span> to smaller than <span class="math inline">\(\epsilon\)</span> is given by <span class="math display">\[
k=\left[\frac{\log \epsilon }{\log \rho(Q)}\right]+1
\]</span> where <span class="math inline">\([a]\)</span> denotes the largest integer less than or equal to <span class="math inline">\(a\)</span>.</p></li>
</ol>
<h3 id="convergence-rate-for-the-steepest-descent-method-for-strongly-convex-function">4.1.2 Convergence rate for the steepest descent method for strongly convex function</h3>
<p>Let <span class="math inline">\(S\subset \mathbb R^n\)</span> be a convex set and <span class="math inline">\(f:S\rightarrow \mathbb R\)</span> a convex function. We assume that <span class="math inline">\(f\)</span> is strongly convex with parameter <span class="math inline">\(m\)</span> and has <span class="math inline">\(M\)</span>-Lipschitz continuous gradient on <span class="math inline">\(S\)</span>. Then its Hessian satisfies the following property, <span class="math display">\[
mI\preceq H_f(x)\preceq MI\;\forall x\in S.
\]</span> <strong>Lemma</strong></p>
<p>Let <span class="math inline">\(x^*\)</span> be a minimizer. Then <span class="math display">\[
f(x)-\frac{1}{2m}||\nabla f(x)||^2\le f(x^*)\le f(x)-\frac{1}{2M}||\nabla f(x)||^2 \; \forall x\in S.
\]</span> <strong>Theorem</strong></p>
<p>Let <span class="math inline">\(f:\mathbb R^n\rightarrow \mathbb R\)</span> be strongly convex with parameter <span class="math inline">\(m\)</span> and its gradient is <span class="math inline">\(M\)</span>-Lipschitz. Let <span class="math inline">\(x^*\)</span> be the unique of <span class="math inline">\(f\)</span> over <span class="math inline">\(\mathbb R^n\)</span>. Define <span class="math inline">\(E_k = f(x^k)-f(x^*)\)</span>, where <span class="math inline">\(\{x^k\}\)</span> is generated by the steepest descent method with exact linesearch. Then, <span class="math display">\[
E_{k+1}\le E_k-\frac{1}{2M}||\nabla f(x^k)||^2\\
E_{k+1}\le E_k\left(1-\frac{m}{M}\right).
\]</span> Proof.</p>
<p>By using the property of <span class="math inline">\(M\)</span>-Lipschitz, we have <span class="math display">\[
f(y)\le f(x)+\langle \nabla f(x),y-x \rangle+\frac{M}{2}||y-x||^2\;\forall x,y\in\mathbb R^n.
\]</span></p>
<p>If we choose <span class="math inline">\(y=x^k-td^k\)</span>, <span class="math inline">\(d^k=\nabla f(x^k)\)</span> and <span class="math inline">\(x=x^k\)</span>, we have <span class="math display">\[
f(x^k-td^k)\le f(x^k)-t\langle \nabla f(x^k),d^k \rangle+\frac{Mt^2}{2}||d^k||^2.
\]</span> We define the function <span class="math display">\[
f(t)=f(x^k)-t\langle \nabla f(x^k),d^k \rangle+\frac{Mt^2}{2}||d^k||^2.
\]</span> Then we have <span class="math display">\[
f_{\min}=f(\frac{1}{M})=f(x^k)-\frac{1}{2M}||d^k||^2.
\]</span> Therefore, we have <span class="math display">\[
f(x^{k+1})\le f(x^k)-\frac{1}{2M}||d^k||^2.
\]</span> The first inequality can be proved.</p>
<p>For the second inequality, since we have <span class="math display">\[
E_k\le \frac{1}{2m}||\nabla f(x)||^2.
\]</span> Then we have <span class="math inline">\(-||d^k||^2\le -2mE_k\)</span>. The second inequality can be proved.</p>
<p><strong>Remark</strong></p>
<p>From the theorem, we see that <span class="math display">\[
E(x^{k+1})/E(x^1)\le (1-m/M)^k\le \epsilon,
\]</span> which implies that we need the number of iterations <span class="math inline">\(k\)</span> to satisfy <span class="math display">\[
k\ge \frac{\log \epsilon ^{-1}}{\log\rho^{-1}}\approx \frac{m}{M}\log \epsilon^{-1} \;(\text{ if }m/M\ll 1),
\]</span> where <span class="math inline">\(\rho = 1-m/M\)</span>.</p>
<h2 id="line-search-strategies">4.2 Line search strategies</h2>
<ol type="1">
<li><p>Minimization rule = exact line search. <span class="math display">\[
\alpha_k=\arg\min\{f(x^k+\alpha d^k)\;|\;\alpha \ge 0\}.
\]</span> If the line search interval is limited to <span class="math inline">\(\alpha \in [0,\bar \alpha]\)</span>, it is called limited minimization rule.</p></li>
<li><p>Armijo rule (<strong>backtracking</strong> method).</p>
<p>Let <span class="math inline">\(\sigma\in(0,0.5)\)</span> and <span class="math inline">\(\beta\in (0,1)\)</span>. Start with <span class="math inline">\(\bar\alpha\)</span> and continue with $=,,$ until the following inequality is satisfied, <span class="math display">\[
f(x^k+\alpha d^k)\le f(x^k)+\alpha\sigma\langle \nabla f(x^k),d^k\rangle.
\]</span> Let <span class="math inline">\(r\)</span> be the first integer satisfying the inequality. Set <span class="math inline">\(\alpha_k=\beta^r\bar \alpha\)</span>.</p></li>
<li><p>Non-monotone line search. <span class="math display">\[
f(x^k+\alpha d^k)\le \max \{f(x^{k-l}),\dotsm,f(x^k)\}+\alpha \sigma \langle \nabla f(x^k),d^k\rangle.
\]</span></p></li>
</ol>
<h2 id="accelerated-proximal-gradient-method-for-convex-programming">4.3 Accelerated proximal gradient method for convex programming</h2>
<p>Consider a smooth convex function <span class="math inline">\(f\)</span> with <span class="math inline">\(L\)</span>-Lipschitz continuous gradient. We are interested in solving <span class="math display">\[
\min \{F(x)=f(x)+g(x)\;|\;x\in \mathbb R^n\},
\]</span> where <span class="math inline">\(g:\mathbb R^n\rightarrow (-\infty,\infty]\)</span> is a proper closed convex function.</p>
<p><strong>Example</strong></p>
<p>In sparse regression problem, <span class="math inline">\(f(x)=\frac{1}{2}||Ax-b||^2\)</span> and <span class="math inline">\(g(x)=\rho ||x||_1\)</span>.</p>
<p>For a given <span class="math inline">\(\bar x\)</span> and <span class="math inline">\(H\succeq 0\)</span>, consider the convex quadratic function, <span class="math display">\[
q(x;\bar x)= f(\bar x)+\langle \nabla f(\bar x),x-\bar x\rangle +\frac{1}{2}\langle x-\bar x,H(x-\bar x)\rangle.
\]</span> At the current point <span class="math inline">\(\bar x\)</span>, proximal gradient and APG methods solve a sub-problem of the form, <span class="math display">\[
\hat x =\arg \min \{g(x)+q(x;\bar x)\;|\;x\in \mathbb R^n\}.
\]</span> <strong>Accelerated proximal gradient (APG) method</strong></p>
<p>Given a positive sequence <span class="math inline">\(\{t_k\}\)</span> such that <span class="math inline">\(t_{k+1}^2-t_{k+1}\le t_k^2\)</span> starting with <span class="math inline">\(t_0=1\)</span>, <span class="math inline">\(t_1=1\)</span>. Given <span class="math inline">\(x^0\)</span>. For <span class="math inline">\(k=0,1,\dots\)</span>, do the following iterations.</p>
<p><strong>[Step 1]</strong> Set <span class="math inline">\(\beta_k=(t_k-1)/t_{k+1}\)</span> and <span class="math inline">\(\bar x^k=x^k+\beta_k(x^k-x^{k-1})\)</span>.</p>
<p><strong>[Step 2]</strong> Compute <span class="math display">\[
x^{k+1}=\arg \min \{g(x)+q(x;\bar x^k)\;|\;x\in \mathbb R^n\}.
\]</span> When <span class="math inline">\(t_k=1\)</span> for all <span class="math inline">\(k\)</span>, then <span class="math inline">\(\bar x^k=x^k\)</span> for all <span class="math inline">\(k\)</span>, and the method is the standard <strong>proximal gradient method</strong>.</p>
<p><strong>Lemma</strong></p>
<p>Assume that <span class="math inline">\(f(\hat x)\le q(\hat x;\bar x)\)</span>. (This assumption can be satisfied by choosing <span class="math inline">\(H\)</span>) Then we have the following <strong>decent property</strong>, <span class="math display">\[
F(x)+\frac{1}{2}||x-\bar x||_H^2\ge F(\hat x)+\frac{1}{2}||x-\hat x||_H^2\;\forall x\in \mathbb R^n.
\]</span> Proof.</p>
<p>We have <span class="math display">\[
\begin{array}{rCl}
F(x)-F(\hat x)&amp;=&amp;F(x)-f(\hat x)-g(\hat x)\\
&amp;\ge&amp; F(x)-q(\hat x;\bar x)-g(\hat x)\\
&amp;=&amp; g(x)-g(\hat x)+f(x)-f(\bar x)-\langle \nabla f(\bar x),\hat x-\bar x\rangle-\frac{1}{2}||\hat x-\bar x||_H^2.
\end{array}
\]</span> By convexity of <span class="math inline">\(g\)</span> and <span class="math inline">\(f\)</span>, we have <span class="math display">\[
g(x)-g(\hat x)\ge \langle \lambda,x-\hat x\rangle\quad \lambda \in \partial g(\hat x)\\
f(x)-f(\bar x)\ge \langle \nabla f(\bar x),x-\bar x\rang.
\]</span> Then we have <span class="math display">\[
F(x)-F(\hat x)\ge \langle \lambda+\nabla f(\bar x),x-\hat x\rangle -\frac{1}{2}||\hat x-\bar x||_H^2.
\]</span> From the optimality condition, we have <span class="math display">\[
0\in \partial g(\hat x)+\nabla f(\bar x)+H(\hat x-\bar x)\\
\implies\\
\lambda +\nabla f(\bar x)= H(\bar x-\hat x).
\]</span> Then we have <span class="math display">\[
F(x)-F(\hat x)\ge \langle H(\bar x-\hat x),x-\hat x\rangle -\frac{1}{2}||\hat x-\bar x||_H^2\\
=\frac{1}{2}||x-\hat x||_H^2-\frac{1}{2}||x-\bar x||_H^2.
\]</span> Q.E.D.</p>
<p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\(x^*\)</span> be a minimizer of <span class="math inline">\(F(\cdot)\)</span>. Define <span class="math inline">\(E(\cdot)=F(\cdot)-F(x^*)\ge 0\)</span>. Assume that <span class="math inline">\(f(x^{k+1})\le q(x^{k+1};\bar x^k)\)</span> for all <span class="math inline">\(k\)</span>. Then <span class="math display">\[
E(x^{k+1})\le \frac{1}{2t_{k+1}^2}||x^*-x^0||_H^2.
\]</span> In practice, the sequence <span class="math inline">\(\{t_k\}\)</span> is typically defined recursively as follows, <span class="math display">\[
t_{k+1}=\frac{1+\sqrt{1+4t_k^2}}{2}\implies t_k\ge \frac{k}{2}\quad \forall k\ge 1
\]</span> Hence, <span class="math display">\[
0\le F(x^k)-F(x^*)\le \frac{1}{2t_k^2}||x^*-x^0||_H^2\le \frac{2}{k^2}||x^*-x^0||_H^2.
\]</span> That is, the iteration complexity of APG is <span class="math inline">\(O(1/k^2)\)</span>.</p>
<p><strong>Theorem</strong></p>
<p>Assume that <span class="math inline">\(f(x^{k+1})\le q(x^{k+1};\bar x^k)\)</span> for all <span class="math inline">\(k\)</span>. If <span class="math inline">\(t_k=1\)</span> for all <span class="math inline">\(k\)</span>. Then <span class="math display">\[
kE(x^k)+\frac{1}{2}||x^k-x^*||_H^2\le E(x^1)+\frac{1}{2}||x^1-x^*||_H^2\le \frac{1}{2}||x^0-x^*||_H^2.
\]</span> Hence <span class="math display">\[
0\le F(x^k)-F(x^*)\le \frac{1}{2k}||x^0-x^*||_H^2.
\]</span> That is, the iteration complexity of the proximal gradient method is <span class="math inline">\(O(1/k)\)</span>.</p>
<p><strong>Example</strong></p>
<p>Consider the sparse regression problem, <span class="math display">\[
\min \left\{\frac{1}{2}||Ax-b||^2+\rho||x||_1\;|\; x\in\mathbb R^n\right\},
\]</span> where <span class="math inline">\(A\in \mathbb R^{m\times n}\)</span>, <span class="math inline">\(b\in \mathbb R^m\)</span> and <span class="math inline">\(\rho\)</span> are given data. Let <span class="math inline">\(f(x)=\frac{1}{2}||Ax-b||^2\)</span> and <span class="math inline">\(g(x)=\rho||x||_1\)</span>. Then <span class="math inline">\(\nabla f(x)=A^T(Ax-b)\)</span> is Lipschitz continuous with modulus <span class="math inline">\(L=\lambda_\max(AA^T)\)</span>. Pick <span class="math inline">\(H=LI_n\)</span>, the APG subproblem is given by <span class="math display">\[
\begin{array}{rCl}
x^{k+1}&amp;=&amp;\arg\min_{x}\left\{g(x)+\langle \nabla f(\bar x^k),x-\bar x^k\rangle +\frac{L}{2}||x-\bar x^k||^2\;|\; x\in\mathbb R^n\right\}\\
&amp;=&amp;\arg\min_x\left\{ \rho||x||_1+\frac{L}{2}(x-\bar x^k+\frac{2}{L}\nabla f(\bar x^k))^2-\frac{2}{L}||\nabla f(\bar x^k)||^2\right\}\\
&amp;=&amp;\arg\min_x\left\{ \rho||x||_1+\frac{L}{2}[x-(\bar x^k-\frac{2}{L}\nabla f(\bar x^k))]^2\right\}
\end{array}
\]</span> Then if we define <span class="math inline">\(y^k=\bar x^k-\frac{2}{L}\nabla f(\bar x^k)\)</span>, we have <span class="math display">\[
\begin{array}{rCl}
x^{k+1}&amp;=&amp;\arg\min_x\left\{ \rho||x||_1+\frac{L}{2}||x-y^k||^2\right\}\\
&amp;=&amp; P_{\lambda f}\left(\bar x^k-\lambda\nabla f(\bar x^k)\right).
\end{array}
\]</span> where <span class="math inline">\(\lambda = 2/L\)</span> and <span class="math inline">\(f=\rho||x||_1\)</span>. It is easy to see that <span class="math display">\[
P_{\lambda f}(x)=\text{sign}(x)\circ \max \{|x|-\lambda,0\}.
\]</span> <strong>Example</strong></p>
<p>Given <span class="math inline">\(G\in \mathbb S^n\)</span>, consider the projection problem onto the closed convex cone <span class="math inline">\(DNN_n^*=\mathbb S_+^N+\mathcal N^n\)</span>. This problem can be formulated as, <span class="math display">\[
\begin{array}{rcl}
&amp;&amp;\min\left\{\frac{1}{2}||S+Z-G||^2\;|\;S\in\mathbb S^n_+,\;Z\in\mathcal N^n\right\}\\
&amp;=&amp;\min\left\{\frac{1}{2}||Z-(G-S)||^2\;|\;S\in\mathbb S^n_+,\;Z\in\mathcal N^n\right\}\\
&amp;=&amp;\min\left\{\frac{1}{2}||\Pi_{\mathcal N^n}(S-G)||^2\;|\;S\in\mathbb S^n_+\right\}\\
&amp;=&amp;\min\left\{\frac{1}{2}||\Pi_{\mathcal N^n}(S-G)||^2+\delta_{\mathbb S_+^n}(S)\right\}.
\end{array}
\]</span> This can be shown by <span class="math display">\[
\begin{array}{rcl}
&amp;&amp;\min \left\{\frac{1}{2}||Z-A||^2\;|\; Z\in\mathcal N^n\right\}\\
&amp;=&amp;\min \left\{\delta_{\mathcal N^n}(Z)+\frac{1}{2}||Z-A||^2\right\}\\
&amp;=&amp;P_f(A)\\
&amp;=&amp; \Pi_{\mathcal N^n}(A).
\end{array}
\]</span> Or by checking the following property <span class="math display">\[
\begin{array}{rcl}
A&amp;=&amp;P_f(A)+P_{f^*}(A)\\
&amp;=&amp;\Pi_{\mathcal N^n}(A)+\Pi_{-\mathcal N^n}(A)\\
&amp;=&amp;\Pi_{\mathcal N^n}(A)-\Pi_{\mathcal N^n}(-A).
\end{array}
\]</span> We can also obtain the same result.</p>
<p>We define <span class="math inline">\(f(S)=\frac{1}{2}||\Pi_{\mathcal N^n}(S-G)||^2\)</span>. From the optimality condition, we have <span class="math display">\[
\begin{array}{rcl}
0&amp;\in&amp;\nabla f(\bar S)+\partial \delta_{\mathbb S_+^n}\quad \text{$f(\bar S)$ is differentiable}.\\
-\nabla f(\bar S)&amp;\in&amp; \partial \delta_{\mathbb S_+^n}(S)\\
\bar S-\nabla f(\bar S)&amp;\in&amp; (I+\partial \delta_{\mathbb S_+^n})(\bar S)
\end{array}
\]</span> Then we have <span class="math display">\[
\bar S=(I+\partial \delta_{\mathbb S_+^n})^{-1}(\bar S-\nabla f(\bar S))=\Pi_{\mathbb S_+^n}(\bar S-\nabla f(\bar S)).
\]</span> We have <span class="math display">\[
\nabla f(S)=\Pi_{\mathcal N^n}(S-G),
\]</span> and <span class="math display">\[
\begin{array}{rcl}
||\nabla f(S)-\nabla f(S&#39;)||&amp;=&amp;||\Pi_{\mathcal N^n}(S-G)-\Pi_{\mathcal N^n}(S&#39;-G)||\\
&amp;\le &amp; ||(S-G)-(S&#39;-G)||\\
&amp;=&amp; ||S-S&#39;||.
\end{array}
\]</span> Therefore <span class="math inline">\(\nabla f(\cdot)\)</span> is Lipschitz continuous with modulus <span class="math inline">\(L=1\)</span>. Pick <span class="math inline">\(H=LI_n\)</span>, the APG subproblem is given by <span class="math display">\[
S^{k+1}=\Pi\left(\bar S-\nabla f(\bar S)\right).
\]</span></p>
<h2 id="gradient-projection-method">4.4 Gradient projection method</h2>
<p>Let <span class="math inline">\(f:Q\rightarrow \mathbb R\)</span> be a continuously differentiable function (not necessarily convex) defined on a closed convex subset <span class="math inline">\(Q\)</span> of <span class="math inline">\(\mathbb R^n\)</span> with <span class="math inline">\(L\)</span>-Lipschitz continuous gradient. Consider <span class="math display">\[
\min\{f(x)\;|\; x\in Q\}.
\]</span> We say that <span class="math inline">\(\bar x\in Q\)</span> is a stationary point if <span class="math display">\[
\langle \nabla f(\bar x),y-\bar x\rangle \ge 0\quad\forall y\in Q.
\]</span> The gradient projection method generate a sequence of iterates as follows, <span class="math display">\[
x^{k+1}=P_Q(x^k-\alpha \nabla f(x^k)).
\]</span> For each <span class="math inline">\(x\in Q\)</span>, let <span class="math display">\[
x(\alpha )=x-\alpha\nabla f(x),\quad x_Q(\alpha )=P_Q(x(\alpha)).
\]</span></p>
<h2 id="stochastic-gradient-descent-method">4.5 Stochastic gradient descent method</h2>
<p>Suppose <span class="math inline">\(\tilde Z\)</span> is an n-dimensional random variable with mean <span class="math inline">\(\mu \in \mathbb R^n\)</span>. Consider the following problem, <span class="math display">\[
\min_{x\in\mathbb R^n}h(x)=\frac{1}{2}\mathbb E[||x-\tilde Z||^2],
\]</span> where <span class="math inline">\(\mathbb E(\cdot)\)</span> denotes the expectation with respect to the distribution of <span class="math inline">\(Z\)</span>, i.e., <span class="math display">\[
E[||x-\tilde Z||^2]=\int ||x-\tilde Z(w)||^2dP(w).
\]</span> If <span class="math inline">\(Z\)</span> is a discrete random variable, then <span class="math display">\[
E[||x-\tilde Z||^2]=\sum_{i=1}^Np_i||x-a_i||^2.
\]</span> In practice, to solve this problem, one may draw <span class="math inline">\(m\)</span> independent identically distributed samples of <span class="math inline">\(\tilde Z\)</span>, say <span class="math inline">\(S=\{z_1,\dots,z_m\}\)</span>, and then solve <span class="math display">\[
\min_{x\in\mathbb R^n}F_S(x)=\frac{1}{m}\sum_{i=1}^m \frac{1}{2}||x-z_i||^2.
\]</span> The corresponding optimality condition is <span class="math display">\[
0=\nabla F_S(x)=\frac{1}{m}\sum_{i=1}^m(x-z_i)\implies x=\frac{1}{m}\sum_{i=1}^mz_i.
\]</span></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme â€“ <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
